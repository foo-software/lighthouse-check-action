{
	"name": "robots-parser",
	"version": "2.4.0",
	"description": "NodeJS robots.txt parser with support for wildcard (*) matching.",
	"keywords": [
		"robots.txt",
		"parser",
		"user-agent",
		"scraper",
		"spider",
		"bot",
		"robots-exclusion-standard"
	],
	"main": "index.js",
	"directories": {
		"test": "tests"
	},
	"scripts": {
		"test": "nyc --reporter=text-summary --reporter=html --reporter=lcovonly mocha"
	},
	"repository": {
		"type": "git",
		"url": "https://github.com/samclarke/robots-parser.git"
	},
	"author": "Sam Clarke <sam@samclarke.com>",
	"license": "MIT",
	"files": [
		"/Robots.js",
		"/index.js",
		"/index.d.ts"
	],
	"prettier": {
		"tabWidth": 4,
		"useTabs": true,
		"singleQuote": true,
		"trailingComma": "none"
	},
	"devDependencies": {
		"chai": "^4.3.4",
		"mocha": "^9.1.3",
		"nyc": "^15.1.0"
	},
	"types": "./index.d.ts"
}
